---
permalink: /
title: "Tieyuan Chen (ÈôàÈìÅÊ∫ê)"
excerpt: "Ph.D. Student at SJTU"
author_profile: false
redirect_from: 
  - /about/
  - /about.html
---

<div id="main-content">

<!-- ‰∏™‰∫∫ÁÆÄ‰ªãÊùøÂùóÔºöÂ∑¶ÊñáÂè≥Âõæ -->
<div style="display: flex; gap: 20px; align-items: flex-start; flex-wrap: wrap;">
  <div style="flex: 2; min-width: 300px;">
    <h1>üëã About Me</h1>
    <p>
      Hello! I am <strong>Tieyuan Chen (ÈôàÈìÅÂÖÉ)</strong>, a third-year Ph.D. student (2023‚Äìpresent) at 
      <a href="https://en.sjtu.edu.cn/">Shanghai Jiao Tong University (SJTU)</a>, 
      <a href="https://english.seiee.sjtu.edu.cn/">School of Electronic Information and Electrical Engineering (SEIEE)</a>, 
      advised by Prof. <a href="https://weiyaolin.github.io/">Weiyao Lin</a>.
    </p>
    <p>
      Currently, I am a Research Intern at <strong>AGI Center, Ant Research Institute</strong> (Mar. 2025 ‚Äì Present), working with 
      <a href="https://sites.google.com/site/leeplus/">Jianguo Li</a>, 
      <a href="https://tlin-taolin.github.io/">Tao Lin</a>, 
      <a href="https://chenhaoxing.github.io/">Haoxing Chen</a>, and 
      <a href="https://r00kie-liu.github.io/">Huabin Liu</a>.
    </p>
    <p>
      I received my B.Eng. degree from <strong>Sichuan University (SCU)</strong> (2019‚Äì2023), ranking <strong>1 / 29</strong>. I was also selected for the Joint PhD Program at <a href="https://www.bjzgca.edu.cn/en/">Beijing Zhongguancun Academy</a>.
    </p>
    <p>
      My research goal is to build intelligent systems capable of complex <strong>Video Reasoning</strong> and <strong>Causal Discovery</strong>. I have published <strong>four first-author papers</strong> in top-tier venues including <strong>TPAMI, NeurIPS, ICLR, and TCSVT</strong>.
    </p>
    
    <!-- Á§æ‰∫§ÈìæÊé•ÊåâÈíÆ -->
    <div style="margin-top: 15px;">
      <a href="mailto:tieyuanchen@sjtu.edu.cn"><img src="https://img.shields.io/badge/Email-tieyuanchen%40sjtu.edu.cn-blue?style=flat&logo=gmail" alt="Email"></a>
      <a href="https://scholar.google.com/citations?user=YOUR_ID"><img src="https://img.shields.io/badge/Google_Scholar-Tieyuan_Chen-grey?style=flat&logo=google-scholar" alt="Google Scholar"></a>
      <a href="https://github.com/tychen-SJTU"><img src="https://img.shields.io/badge/Github-tychen--SJTU-black?style=flat&logo=github" alt="Github"></a>
    </div>
  </div>

  <!-- Â§¥ÂÉèÂå∫Âüü (ËØ∑ÊõøÊç¢ your_photo.jpg) -->
  <div style="flex: 1; text-align: center; min-width: 200px;">
    <img src="../me.jpg" alt="Tieyuan Chen" style="border-radius: 50%; width: 220px; height: 220px; object-fit: cover; box-shadow: 0 4px 8px rgba(0,0,0,0.1);">
  </div>
</div>

---

<!-- Êñ∞ÈóªÊùøÂùó -->
## üî• News
<ul>
  <li><strong>[Mar. 2025]</strong> Started research internship at <strong>Ant Research Institute (AGI Center)</strong>.</li>
  <li><strong>[Feb. 2026]</strong> One paper accepted by <strong>ICLR 2026</strong>.</li>
  <li><strong>[Jan. 2025]</strong> Two papers accepted by <strong>IEEE TPAMI</strong> and <strong>IEEE TCSVT</strong>.</li>
  <li><strong>[Sep. 2024]</strong> Selected for the Joint PhD Program at <strong>Beijing Zhongguancun Academy</strong>.</li>
  <li><strong>[Sep. 2024]</strong> One paper accepted by <strong>NeurIPS 2024 (Spotlight)</strong>.</li>
</ul>

---

<!-- Á†îÁ©∂ÂÖ¥Ë∂£ -->
## üî¨ Research Interests
<div style="display: flex; gap: 10px; flex-wrap: wrap;">
  <span style="background-color: #f0f0f0; padding: 5px 10px; border-radius: 5px;">üé• Video Understanding & Reasoning</span>
  <span style="background-color: #f0f0f0; padding: 5px 10px; border-radius: 5px;">üß† LLMs & Multimodal LLMs</span>
  <span style="background-color: #f0f0f0; padding: 5px 10px; border-radius: 5px;">üîó Causal Discovery</span>
</div>

---

<!-- ËÆ∫ÊñáÊùøÂùóÔºö‰ΩøÁî® HTML Table Â∏ÉÂ±ÄÂÆûÁé∞Â∑¶ÂõæÂè≥Êñá -->
## üìù Selected Publications

<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">

  <!-- Paper 1: NeurIPS 2024 -->
  <tr>
    <td style="padding:20px;width:30%;vertical-align:middle">
      <img src="../main_mecd.png" alt="MECD" style="width:100%; max-width:250px; border-radius:5px; box-shadow:0 2px 5px rgba(0,0,0,0.1)">
    </td>
    <td style="padding:20px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2409.17647">
        <span style="font-weight:bold; font-size:1.1em;">MECD: Unlocking Multi-Event Causal Discovery in Video Reasoning</span>
      </a>
      <br>
      <strong>Tieyuan Chen</strong>, Huabin Liu, Tianyao He, Yihang Chen, Chaofan Gan, Xiao Ma, Cheng Zhong, Yang Zhang, Yingxue Wang, Hui Lin, Weiyao Lin
      <br>
      <em>NeurIPS 2024</em> <span style="color:#d9534f; font-weight:bold;">(Spotlight, Top 2.4%)</span>
      <br>
      <a href="https://arxiv.org/abs/2409.17647"><img src="https://img.shields.io/badge/arXiv-2409.17647-b31b1b.svg?logo=arXiv" alt="arXiv"></a>
      <a href="https://github.com/tychen-SJTU/MECD-Benchmark"><img src="https://img.shields.io/badge/Code-GitHub-black?logo=github" alt="GitHub"></a>
    </td>
  </tr>

  <!-- Paper 2: ICLR 2026 -->
  <tr>
    <td style="padding:20px;width:30%;vertical-align:middle">
      <img src="../main_dnd.png" alt="DND" style="width:100%; max-width:250px; border-radius:5px; box-shadow:0 2px 5px rgba(0,0,0,0.1)">
    </td>
    <td style="padding:20px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2510.11001">
        <span style="font-weight:bold; font-size:1.1em;">DND: Boosting Large Language Models with Dynamic Nested Depth</span>
      </a>
      <br>
      <strong>Tieyuan Chen</strong>, Xiaodong Chen, Haoxing Chen, Zhenzhong Lan, Weiyao Lin, Jianguo Li
      <br>
      <em>International Conference on Learning Representations (ICLR), 2026</em>
      <br>
      <a href="https://arxiv.org/abs/2510.11001"><img src="https://img.shields.io/badge/arXiv-2510.11001-b31b1b.svg?logo=arXiv" alt="arXiv"></a>
    </td>
  </tr>

  <!-- Paper 3: TPAMI -->
  <tr>
    <td style="padding:20px;width:30%;vertical-align:middle">
      <img src="../main_mecd2.png" alt="MECD+" style="width:100%; max-width:250px; border-radius:5px; box-shadow:0 2px 5px rgba(0,0,0,0.1)">
    </td>
    <td style="padding:20px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2501.07227">
        <span style="font-weight:bold; font-size:1.1em;">MECD+: Unlocking Event-Level Causal Graph Discovery for Video Reasoning</span>
      </a>
      <br>
      <strong>Tieyuan Chen</strong>, Huabin Liu, Yi Wang, Yihang Chen, Tianyao He, Chaofan Gan, Huanyu He, Weiyao Lin
      <br>
      <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</em>
      <br>
      <a href="https://arxiv.org/abs/2501.07227"><img src="https://img.shields.io/badge/arXiv-2501.07227-b31b1b.svg?logo=arXiv" alt="arXiv"></a>
      <a href="https://github.com/tychen-SJTU/MECD-Benchmark"><img src="https://img.shields.io/badge/Code-GitHub-black?logo=github" alt="GitHub"></a>
    </td>
  </tr>

  <!-- Paper 4: TCSVT -->
  <tr>
    <td style="padding:20px;width:30%;vertical-align:middle">
      <img src="../main_csta.png" alt="CSTA" style="width:100%; max-width:250px; border-radius:5px; box-shadow:0 2px 5px rgba(0,0,0,0.1)">
    </td>
    <td style="padding:20px;width:70%;vertical-align:middle">
      <a href="https://arxiv.org/abs/2501.07236">
        <span style="font-weight:bold; font-size:1.1em;">CSTA: Spatial-Temporal Causal Adaptive Learning for Exemplar-Free Video Class-Incremental Learning</span>
      </a>
      <br>
      <strong>Tieyuan Chen</strong>, Huabin Liu, Chern Hong Lim, John See, Xing Gao, Junhui Hou, Weiyao Lin
      <br>
      <em>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</em>
      <br>
      <a href="https://arxiv.org/abs/2501.07236"><img src="https://img.shields.io/badge/arXiv-2501.07236-b31b1b.svg?logo=arXiv" alt="arXiv"></a>
      <a href="https://github.com/tychen-SJTU/CSTA"><img src="https://img.shields.io/badge/Code-GitHub-black?logo=github" alt="GitHub"></a>
    </td>
  </tr>
</table>

---

## ü•á Honors and Awards
*   **2023**: Sichuan Province Outstanding Graduate (Top 3%)
*   **2022**: **China National Scholarship** (Top 1%)
*   **2022**: Sichuan University Comprehensive Special Scholarship (Top 0.1%)
*   **2022**: Sichuan University Hundred Excellent Student (Top 0.2%)
*   **2021**: **China National Scholarship** (Top 1%)

---

## üìä Academic Service

**Reviewer for Conferences**
*   **2026**: CVPR, ECCV, ICLR, ICML, ICME
*   **2025**: CVPR, ICCV, NeurIPS, ICLR, AAAI, ICME, PRCV

**Reviewer for Journals**
*   Journal of Visual Communication and Image Representation (JVCIR)
*   Signal Processing: Image Communication (SPIC)

<br>
<center>
<p style="font-size: small; color: #888;">Last updated: Feb. 2026</p>
</center>

</div>